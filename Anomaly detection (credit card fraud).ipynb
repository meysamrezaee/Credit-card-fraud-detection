{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data from\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly (fraud) detection in credit cards\n",
    "- A low precision score means more employee hour for investigating suspicious transactions and therefore more cost to the company.\n",
    "- A low recall means that we miss fraudulent activities that need to be identified by the model.\n",
    "- Minimizing false negatives (High recall score) is slightly more important to us than minimizing false positives (high precision score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_path = '../Datasets/creditcard.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any missing values?\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of frauds: 492\n",
      "number of normal: 284315\n",
      "Anomaly to normal ratio: 0.0017304750013189597\n"
     ]
    }
   ],
   "source": [
    "nNormal = df[df['Class'] == 0].shape[0]\n",
    "nFraud = df[df['Class'] == 1].shape[0]\n",
    "anomalyFraction = nFraud / nNormal\n",
    "print('number of frauds: {}'.format(nFraud))\n",
    "print('number of normal: {}'.format(nNormal))\n",
    "print('Anomaly to normal ratio: {}'.format(anomalyFraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class.copy()\n",
    "X = df.drop(['Class'], axis=1, inplace=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 30) (199364,)\n",
      "(85443, 30) (85443,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- precision = TP / (TP+FP)\n",
    "- recall = TP / (TP+FN)\n",
    "- f-score = (2 x precision x recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of anomalies: 136\n"
     ]
    }
   ],
   "source": [
    "print('Number of anomalies: {}'.format(sum(y_test == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printErrors(y_pred):\n",
    "    print('Recall score', recall_score(y_test, y_pred))\n",
    "    print('Precision score', precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meysam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score 0.03676470588235294\n",
      "Precision score 0.0015571473061351605\n"
     ]
    }
   ],
   "source": [
    "model = OneClassSVM(kernel='linear', degree=2, gamma='scale', nu=0.1, max_iter=10)\n",
    "model.fit(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred == -1] = 0\n",
    "printErrors(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score 0.3088235294117647\n",
      "Precision score 0.3088235294117647\n"
     ]
    }
   ],
   "source": [
    "model = IsolationForest(n_estimators=50, max_samples=10000, contamination=anomalyFraction, max_features=0.1)\n",
    "model.fit(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "printErrors(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score 0.1323529411764706\n",
      "Precision score 0.125\n"
     ]
    }
   ],
   "source": [
    "model = LocalOutlierFactor(n_neighbors=6, algorithm='auto', leaf_size=10, \n",
    "                           metric='minkowski', p=1, metric_params=None, contamination=anomalyFraction)\n",
    "# Since it is a neighborhood based model, we need to merge test and train data (my own understanding)\n",
    "X_full = pd.concat([X_train, X_test], ignore_index=True)\n",
    "y_pred = model.fit_predict(X_full)\n",
    "y_pred = y_pred[-y_test.shape[0]:]\n",
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "printErrors(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "ros = RandomUnderSampler(random_state=2)\n",
    "X_train_small, y_train_small = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For grid search\n",
    "def findBestParameters(model, train_X, train_y):\n",
    "    modelName = model.__class__.__name__\n",
    "    parameters = {}\n",
    "    if modelName == 'SVC':\n",
    "        parameters = {\n",
    "            'C':[50, 25, 10, 5, 1],\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto']}\n",
    "        \n",
    "    elif modelName == 'RandomForestClassifier':\n",
    "        parameters = {\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_depth': [10, 25, None],\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_leaf': [1, 2, 4]}\n",
    "        \n",
    "    elif modelName == 'MLPClassifier':\n",
    "        parameters = {\n",
    "            'hidden_layer_sizes': [(5), (10), (20), \n",
    "                        (5, 5), (10, 10), (20, 20),\n",
    "                        (5, 5, 5), (10, 10, 10), (20, 20, 20)],\n",
    "            'max_iter': [500, 1000]}\n",
    "    elif modelName == 'LogisticRegression':\n",
    "        parameters = {\n",
    "            'C': [0.1, 1, 5, 10, 25, 50],\n",
    "            'max_iter': [100, 500, 1000]}\n",
    "    \n",
    "    clf = GridSearchCV(model, param_grid=parameters, cv=5)\n",
    "    clf.fit(train_X, train_y)\n",
    "    print('Best parameters for', modelName, '\\n', clf.best_params_)\n",
    "    \n",
    "    if modelName == 'SVC':\n",
    "        return SVC(C=clf.best_params_['C'], \n",
    "                   gamma=clf.best_params_['gamma'], \n",
    "                   kernel=clf.best_params_['kernel'])\n",
    "    elif modelName == 'RandomForestClassifier':\n",
    "        return RandomForestClassifier(n_estimators=clf.best_params_['n_estimators'], \n",
    "                                      max_depth=clf.best_params_['max_depth'],\n",
    "                                     max_features=clf.best_params_['max_features'], \n",
    "                                      min_samples_leaf=clf.best_params_['min_samples_leaf'])\n",
    "    elif modelName == 'MLPClassifier':\n",
    "        return MLPClassifier(hidden_layer_sizes=clf.best_params_['hidden_layer_sizes'], \n",
    "                             max_iter= clf.best_params_['max_iter'])\n",
    "    elif modelName == 'LogisticRegression':\n",
    "        return LogisticRegression(C=clf.best_params_['C'],\n",
    "                                  max_iter= clf.best_params_['max_iter'])\n",
    "    \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression \n",
      " {'C': 25}\n",
      "\n",
      "Best parameters for SVC \n",
      " {'C': 5, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "\n",
      "Best parameters for MLPClassifier \n",
      " {'hidden_layer_sizes': (20, 20, 20), 'max_iter': 1000}\n",
      "\n",
      "Best parameters for RandomForestClassifier \n",
      " {'max_depth': 25, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')# dont show warnings\n",
    "allModels = [LogisticRegression(), SVC(), MLPClassifier(), RandomForestClassifier()]\n",
    "for i, m in enumerate(allModels):\n",
    "    m = findBestParameters(m, X_train_small, y_train_small)\n",
    "    m.probability = True # need this for changing thresholds later\n",
    "    m.fit(X_train_small, y_train_small)\n",
    "    allModels[i] = m\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Precision score 0.09779179810725552\n",
      "Recall score 0.9117647058823529\n",
      "\n",
      "SVC\n",
      "Precision score 0.0574400723654455\n",
      "Recall score 0.9338235294117647\n",
      "\n",
      "MLPClassifier\n",
      "Precision score 0.045454545454545456\n",
      "Recall score 0.9264705882352942\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision score 0.06007568590350047\n",
      "Recall score 0.9338235294117647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in allModels:\n",
    "    print(m.__class__.__name__)\n",
    "    y_pred = m.predict(X_test)\n",
    "    print('Precision score', precision_score(y_test, y_pred))\n",
    "    print('Recall score', recall_score(y_test, y_pred))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "It seems that the models are good at minimizing false negatives, but bad at minimizing false positives. The easy solution is to change the thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_train_large, y_train_large = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398016,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_large.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score 0.06206896551724138\n",
      "Recall score 0.9264705882352942\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1, max_iter=1000)\n",
    "lr.fit(X_train_large, y_train_large)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Precision score', precision_score(y_test, y_pred))\n",
    "print('Recall score', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "a slight improvement in recall at the cost of precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Precision score 0.7441860465116279\n",
      "Recall score 0.7058823529411765\n",
      "\n",
      "SVC\n",
      "Precision score 0.6298342541436464\n",
      "Recall score 0.8382352941176471\n",
      "\n",
      "MLPClassifier\n",
      "Precision score 0.7394366197183099\n",
      "Recall score 0.7720588235294118\n",
      "\n",
      "RandomForestClassifier\n",
      "Precision score 0.8613861386138614\n",
      "Recall score 0.6397058823529411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.99\n",
    "for m in allModels:\n",
    "    print(m.__class__.__name__)\n",
    "    m.probability = True\n",
    "    #y_pred = m.predict(X_test)\n",
    "    y_pred = (m.predict_proba(X_test)[:,1] >= threshold).astype(int)\n",
    "    print('Precision score', precision_score(y_test, y_pred))\n",
    "    print('Recall score', recall_score(y_test, y_pred))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "- The threshold can be set as a number in the range [0.80, 0.999] to get a good balance between recall and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembled\n",
    "Use a two layer ensembled method: First layer is the four models getting part of the training set and predicting probabilities, instead of 0 and 1, of the sample belonging to a class. The second layer is a linear regression model using getting the output of those models and getting trained on the remainder of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427,)\n",
      "(285,)\n"
     ]
    }
   ],
   "source": [
    "X_train_layer1, X_train_layer2, y_train_layer1, y_train_layer2 = \\\n",
    "train_test_split(X_train_small, y_train_small, test_size=0.4, random_state=42)\n",
    "print(y_train_layer1.shape)\n",
    "print(y_train_layer2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression \n",
      " {'C': 50, 'max_iter': 100}\n",
      "\n",
      "Best parameters for SVC \n",
      " {'C': 50, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "Best parameters for MLPClassifier \n",
      " {'hidden_layer_sizes': (20, 20, 20), 'max_iter': 1000}\n",
      "\n",
      "Best parameters for RandomForestClassifier \n",
      " {'max_depth': 25, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')# dont show warnings\n",
    "layer1_models = [LogisticRegression(), SVC(), MLPClassifier(), RandomForestClassifier()]\n",
    "for i, m in enumerate(layer1_models):\n",
    "    m = findBestParameters(m, X_train_layer1, y_train_layer1)\n",
    "    m.probability = True # need this for layer 2\n",
    "    m.fit(X_train_layer1, y_train_layer1)\n",
    "    layer1_models[i] = m\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.114235e-02</td>\n",
       "      <td>1.737018e-02</td>\n",
       "      <td>5.716266e-03</td>\n",
       "      <td>0.042750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.662597e-05</td>\n",
       "      <td>9.284086e-09</td>\n",
       "      <td>1.303647e-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.695099e-01</td>\n",
       "      <td>9.406830e-01</td>\n",
       "      <td>9.776284e-01</td>\n",
       "      <td>0.913056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.796579e-01</td>\n",
       "      <td>9.170129e-01</td>\n",
       "      <td>7.701589e-01</td>\n",
       "      <td>0.869274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.511680e-12</td>\n",
       "      <td>3.000001e-14</td>\n",
       "      <td>3.740585e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LogisticRegression           SVC  MLPClassifier  RandomForestClassifier\n",
       "0        1.114235e-02  1.737018e-02   5.716266e-03                0.042750\n",
       "1        4.662597e-05  9.284086e-09   1.303647e-04                0.000000\n",
       "2        9.695099e-01  9.406830e-01   9.776284e-01                0.913056\n",
       "3        8.796579e-01  9.170129e-01   7.701589e-01                0.869274\n",
       "4        1.511680e-12  3.000001e-14   3.740585e-07                0.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_layer2_inputs = pd.DataFrame()\n",
    "for m in layer1_models:\n",
    "    y_pred_temp = m.predict_proba(X_train_layer2)[:,0]\n",
    "    df_layer2_inputs[m.__class__.__name__] = y_pred_temp\n",
    "df_layer2_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression \n",
      " {'C': 0.1, 'max_iter': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_model = LogisticRegression()\n",
    "layer2_model.probability = True\n",
    "layer2_model = findBestParameters(layer2_model, df_layer2_inputs, y_train_layer2)\n",
    "layer2_model.fit(df_layer2_inputs, y_train_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score 0.7692307692307693\n",
      "Recall score 0.8088235294117647\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.85\n",
    "df_layer2_inputs = pd.DataFrame()\n",
    "for m in layer1_models:\n",
    "    y_pred_temp = m.predict_proba(X_test)[:,0]\n",
    "    df_layer2_inputs[m.__class__.__name__] = y_pred_temp\n",
    "#y_pred = layer2_model.predict(df_layer2_inputs)\n",
    "y_pred = (layer2_model.predict_proba(df_layer2_inputs)[:,1] >= threshold).astype(int)\n",
    "print('Precision score', precision_score(y_test, y_pred))\n",
    "print('Recall score', recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The ensembled method showed better performance than any single method, but it still relies on the threshold to find the right balance between Recall and Precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
